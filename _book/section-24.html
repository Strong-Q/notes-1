<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Notes</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is notes from yufree">
  <meta name="generator" content="bookdown 0.1.5 and GitBook 2.6.7">

  <meta property="og:title" content="Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is notes from yufree" />
  <meta name="github-repo" content="yufree/notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Notes" />
  
  <meta name="twitter:description" content="This is notes from yufree" />
  

<meta name="author" content="Miao YU">

<meta name="date" content="2016-11-19">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="section-23.html">
<link rel="next" href="section-25.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 笔记概述</a></li>
<li class="chapter" data-level="2" data-path="section-2.html"><a href="section-2.html"><i class="fa fa-check"></i><b>2</b> 数据科学家工具箱</a></li>
<li class="chapter" data-level="3" data-path="r.html"><a href="r.html"><i class="fa fa-check"></i><b>3</b> R语言编程</a></li>
<li class="chapter" data-level="4" data-path="section-4.html"><a href="section-4.html"><i class="fa fa-check"></i><b>4</b> 数据获取与整理</a></li>
<li class="chapter" data-level="5" data-path="section-5.html"><a href="section-5.html"><i class="fa fa-check"></i><b>5</b> 探索性数据分析</a></li>
<li class="chapter" data-level="6" data-path="section-6.html"><a href="section-6.html"><i class="fa fa-check"></i><b>6</b> 可复算性研究</a></li>
<li class="chapter" data-level="7" data-path="section-7.html"><a href="section-7.html"><i class="fa fa-check"></i><b>7</b> 统计推断</a></li>
<li class="chapter" data-level="8" data-path="section-8.html"><a href="section-8.html"><i class="fa fa-check"></i><b>8</b> 回归模型</a></li>
<li class="chapter" data-level="9" data-path="section-9.html"><a href="section-9.html"><i class="fa fa-check"></i><b>9</b> 机器学习实战</a></li>
<li class="chapter" data-level="10" data-path="section-10.html"><a href="section-10.html"><i class="fa fa-check"></i><b>10</b> 开发数据产品</a></li>
<li class="chapter" data-level="11" data-path="section-11.html"><a href="section-11.html"><i class="fa fa-check"></i><b>11</b> 统计学习导论</a></li>
<li class="chapter" data-level="12" data-path="section-12.html"><a href="section-12.html"><i class="fa fa-check"></i><b>12</b> 基因组学数据分析</a></li>
<li class="chapter" data-level="13" data-path="tex.html"><a href="tex.html"><i class="fa fa-check"></i><b>13</b> 简明TEX笔记</a></li>
<li class="chapter" data-level="14" data-path="section-14.html"><a href="section-14.html"><i class="fa fa-check"></i><b>14</b> 生物信息学数据库</a></li>
<li class="chapter" data-level="15" data-path="section-15.html"><a href="section-15.html"><i class="fa fa-check"></i><b>15</b> 流行病学导论</a></li>
<li class="chapter" data-level="16" data-path="section-16.html"><a href="section-16.html"><i class="fa fa-check"></i><b>16</b> 化学品与健康</a></li>
<li class="chapter" data-level="17" data-path="section-17.html"><a href="section-17.html"><i class="fa fa-check"></i><b>17</b> 心理学导论笔记</a></li>
<li class="chapter" data-level="18" data-path="section-18.html"><a href="section-18.html"><i class="fa fa-check"></i><b>18</b> 抑郁</a></li>
<li class="chapter" data-level="19" data-path="section-19.html"><a href="section-19.html"><i class="fa fa-check"></i><b>19</b> 贝叶斯统计</a></li>
<li class="chapter" data-level="20" data-path="python.html"><a href="python.html"><i class="fa fa-check"></i><b>20</b> 数据科学与python简介</a></li>
<li class="chapter" data-level="21" data-path="section-21.html"><a href="section-21.html"><i class="fa fa-check"></i><b>21</b> 生存分析</a></li>
<li class="chapter" data-level="22" data-path="section-22.html"><a href="section-22.html"><i class="fa fa-check"></i><b>22</b> 因果分析</a></li>
<li class="chapter" data-level="23" data-path="section-23.html"><a href="section-23.html"><i class="fa fa-check"></i><b>23</b> 系统思维与公共健康</a></li>
<li class="chapter" data-level="24" data-path="section-24.html"><a href="section-24.html"><i class="fa fa-check"></i><b>24</b> 博弈论</a><ul>
<li class="chapter" data-level="24.1" data-path="section-24.html"><a href="section-24.html#section-24.1"><i class="fa fa-check"></i><b>24.1</b> 术语</a></li>
<li class="chapter" data-level="24.2" data-path="section-24.html"><a href="section-24.html#dominate-strategy"><i class="fa fa-check"></i><b>24.2</b> 支配策略（dominate strategy）</a></li>
<li class="chapter" data-level="24.3" data-path="section-24.html"><a href="section-24.html#best-respinse"><i class="fa fa-check"></i><b>24.3</b> 最佳回应（Best respinse）</a></li>
<li class="chapter" data-level="24.4" data-path="section-24.html"><a href="section-24.html#nash-equilibrium"><i class="fa fa-check"></i><b>24.4</b> 纳什均衡（Nash Equilibrium）</a></li>
<li class="chapter" data-level="24.5" data-path="section-24.html"><a href="section-24.html#pareto-optimality"><i class="fa fa-check"></i><b>24.5</b> 帕累托最优（Pareto Optimality）</a></li>
<li class="chapter" data-level="24.6" data-path="section-24.html"><a href="section-24.html#mixed-stratergies"><i class="fa fa-check"></i><b>24.6</b> 混合策略（Mixed stratergies）</a></li>
<li class="chapter" data-level="24.7" data-path="section-24.html"><a href="section-24.html#section-24.7"><i class="fa fa-check"></i><b>24.7</b> 寻找纳什均衡</a></li>
<li class="chapter" data-level="24.8" data-path="section-24.html"><a href="section-24.html#dominated-strategy"><i class="fa fa-check"></i><b>24.8</b> 被支配策略（dominated strategy）</a></li>
<li class="chapter" data-level="24.9" data-path="section-24.html"><a href="section-24.html#maxmin-strategies"><i class="fa fa-check"></i><b>24.9</b> 最大最小策略（Maxmin strategies）</a></li>
<li class="chapter" data-level="24.10" data-path="section-24.html"><a href="section-24.html#section-24.10"><i class="fa fa-check"></i><b>24.10</b> 扩展形式博弈</a></li>
<li class="chapter" data-level="24.11" data-path="section-24.html"><a href="section-24.html#section-24.11"><i class="fa fa-check"></i><b>24.11</b> 完美子博弈</a></li>
<li class="chapter" data-level="24.12" data-path="section-24.html"><a href="section-24.html#section-24.12"><i class="fa fa-check"></i><b>24.12</b> 信息不对称扩展形式博弈</a></li>
<li class="chapter" data-level="24.13" data-path="section-24.html"><a href="section-24.html#section-24.13"><i class="fa fa-check"></i><b>24.13</b> 混合与行为策略</a></li>
<li class="chapter" data-level="24.14" data-path="section-24.html"><a href="section-24.html#section-24.14"><i class="fa fa-check"></i><b>24.14</b> 重复博弈</a></li>
<li class="chapter" data-level="24.15" data-path="section-24.html"><a href="section-24.html#stochastic-game"><i class="fa fa-check"></i><b>24.15</b> 随机博弈（stochastic game）</a></li>
<li class="chapter" data-level="24.16" data-path="section-24.html"><a href="section-24.html#fictitious-play"><i class="fa fa-check"></i><b>24.16</b> 虚拟行动（fictitious play）</a></li>
<li class="chapter" data-level="24.17" data-path="section-24.html"><a href="section-24.html#no-regret-learning"><i class="fa fa-check"></i><b>24.17</b> 无悔学习（No-regret learning）</a></li>
<li class="chapter" data-level="24.18" data-path="section-24.html"><a href="section-24.html#section-24.18"><i class="fa fa-check"></i><b>24.18</b> 无限重复博弈的平衡</a></li>
<li class="chapter" data-level="24.19" data-path="section-24.html"><a href="section-24.html#section-24.19"><i class="fa fa-check"></i><b>24.19</b> 贝叶斯博弈</a></li>
<li class="chapter" data-level="24.20" data-path="section-24.html"><a href="section-24.html#section-24.20"><i class="fa fa-check"></i><b>24.20</b> 联盟博弈</a></li>
<li class="chapter" data-level="24.21" data-path="section-24.html"><a href="section-24.html#shapley-value"><i class="fa fa-check"></i><b>24.21</b> 夏普利值（Shapley Value）</a></li>
<li class="chapter" data-level="24.22" data-path="section-24.html"><a href="section-24.html#section-24.22"><i class="fa fa-check"></i><b>24.22</b> 核心</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="section-25.html"><a href="section-25.html"><i class="fa fa-check"></i><b>25</b> 复杂系统</a></li>
<li class="divider"></li>
<li><a href="https://github.com/yufree/notes" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="section-24" class="section level1">
<h1><span class="header-section-number">笔记 24</span> 博弈论</h1>
<div id="section-24.1" class="section level2">
<h2><span class="header-section-number">24.1</span> 术语</h2>
<ul>
<li>参与者（players） <span class="math inline">\(N= {1,...,n}\)</span></li>
<li>参与者 <span class="math inline">\(i\)</span> 有一组行动（Actions），行动的集合 <span class="math inline">\(a=(a_1,...,a_n) \in A=A_1 \times A_2 \times ... \times A_n\)</span></li>
<li>参与者 <span class="math inline">\(i\)</span> 的每个行为的收益（Payoffs）都可以用 <span class="math inline">\(u_i:A \rightarrow \Re\)</span> 这个函数表示 <span class="math inline">\(u_i(a)\)</span> 表示某个行为产生的收益，<span class="math inline">\(u = (u_i,...,u_n)\)</span>是效用函数的集合</li>
<li>n个参与者的标准博弈（normal form） <span class="math inline">\(\langle N,A,u \rangle\)</span></li>
<li>两人博弈可以用矩阵（matrix）来描述，行代表选手1，列代表选手2，行对应选手1的行动 <span class="math inline">\(a_1 \in A_1\)</span>，列对应选手2的行动 <span class="math inline">\(a_2 \in A_2\)</span>，每个单元列出每个参与者的收益，先行选手，后列选手</li>
<li>纯竞争博弈（Games of Pure competition）：两个参与者收益对立且对于所有行动集合 <span class="math inline">\(a \in A, u_1(a)+u_2(a) = c\)</span>，<span class="math inline">\(c\)</span>是常数，零和博弈是一个常数为0的纯竞争博弈，此时我们只用考虑一个参与者的收益函数就可以了</li>
</ul>
</div>
<div id="dominate-strategy" class="section level2">
<h2><span class="header-section-number">24.2</span> 支配策略（dominate strategy）</h2>
<ul>
<li>行动单一称为纯策略（pure strategies）有一定概率分布的行动策略称为混合策略（mixed strategies）</li>
<li>对于一个参与者，不论其它参与者采取任何策略，某策略都会得到最大的收益</li>
<li><span class="math inline">\(a_i \in a_i\)</span> 为强支配策略当且仅当参与者<span class="math inline">\(i\)</span> 的收益 <span class="math inline">\(u_i(a_i,a_{-i}) &gt; u_i(a&#39;_i,a_{-i})\)</span>，如果 <span class="math inline">\(a&#39;_i = a_i\)</span>，那么为弱支配策略</li>
</ul>
</div>
<div id="best-respinse" class="section level2">
<h2><span class="header-section-number">24.3</span> 最佳回应（Best respinse）</h2>
<ul>
<li>对于一个参与者，当已知其他参与者的行为后，收益最大的策略</li>
<li>参与者<span class="math inline">\(i\)</span>，对于其它参与者的策略<span class="math inline">\(a_{-i} \in a_{-i}\)</span> 的策略如果<span class="math inline">\(u_i(a_i,a_{-i}) \geqslant u_i(a&#39;_i,a_{-i})\)</span></li>
</ul>
</div>
<div id="nash-equilibrium" class="section level2">
<h2><span class="header-section-number">24.4</span> 纳什均衡（Nash Equilibrium）</h2>
<ul>
<li><span class="math inline">\(a = \langle a_1,...,a_n\rangle\)</span> 是一个纯策略纳什均衡当且仅当对于任何一个行为i，有<span class="math inline">\(a_i \in BR(a_{-i})\)</span></li>
<li>如果任何参与者改变行为的收益都不会增加，那么此时进入纳什均衡</li>
<li>纳什均衡是一系列行为的列表，这些行为都是稳定的</li>
<li>支配策略是纳什均衡但反过来不一定对</li>
<li>任何有限博弈都存在一个纳什均衡（纳什1950年提出）</li>
</ul>
</div>
<div id="pareto-optimality" class="section level2">
<h2><span class="header-section-number">24.5</span> 帕累托最优（Pareto Optimality）</h2>
<ul>
<li>某个结果是帕累托最优当且仅当没有其他结果可以全局帕累托支配这个结果</li>
<li>帕累托最优表示某个博弈结果不差于其他博弈结果</li>
<li>纳什均衡不一定是帕累托最优（囚徒困境）</li>
</ul>
</div>
<div id="mixed-stratergies" class="section level2">
<h2><span class="header-section-number">24.6</span> 混合策略（Mixed stratergies）</h2>
<ul>
<li>策略<span class="math inline">\(S_i\)</span>指对于每个参与者行动的概率分布集合</li>
<li>概率 <span class="math inline">\(Pr(a|s) = \prod_{j \in N}s_j(a_j)\)</span></li>
<li>期望收益函数 <span class="math inline">\(u_i(s) = \sum_{a \in A} u_i(a)Pr(a|s)\)</span></li>
<li>随机策略会使对手混乱进入动态，很多博弈只存在混合策略纳什均衡而没有纯策略纳什均衡（石头剪子布）</li>
</ul>
</div>
<div id="section-24.7" class="section level2">
<h2><span class="header-section-number">24.7</span> 寻找纳什均衡</h2>
<ul>
<li>两人博弈可以用线性互补算法（Linear Complementarity）求解</li>
<li>严格说因为一定存在纳什均衡，寻找它不是NPC问题，但是是PPAD问题，后来人证明纳什均衡是PPAD问题</li>
<li>PPAD问题包括P问题的同时属于NP问题，指存在多项式的解，但不好找</li>
<li>P问题指多项式时间可解决的问题</li>
<li>NP问题指多项式时间可验证一个解的问题</li>
<li>NPC问题指NP问题的归约问题，同时也是NP问题，复杂度不断提高，NPC问题的存在让<span class="math inline">\(P = NP\)</span> 问题很难有答案</li>
<li>NP-hard问题指NP问题的归约问题，但不一定是NP问题</li>
</ul>
</div>
<div id="dominated-strategy" class="section level2">
<h2><span class="header-section-number">24.8</span> 被支配策略（dominated strategy）</h2>
<ul>
<li>指不论其他参与者采取任何策略，该策略劣于其他策略</li>
<li>被支配策略永远不会是最佳回应</li>
<li>可以交互地去除掉每个选手的被支配策略</li>
</ul>
</div>
<div id="maxmin-strategies" class="section level2">
<h2><span class="header-section-number">24.9</span> 最大最小策略（Maxmin strategies）</h2>
<ul>
<li>指其他参与者对某参与者最小收益策略下的最大收益策略<span class="math inline">\(arg max_{s_i}min_{s_{-i}}u_i(s_1,s_2)\)</span></li>
<li>最小最大策略指让对方收益最大而自己收益最小的策略<span class="math inline">\(arg min_{s_i}max_{s_{-i}}u_{-i}i(s_1,s_2)\)</span></li>
</ul>
</div>
<div id="section-24.10" class="section level2">
<h2><span class="header-section-number">24.10</span> 扩展形式博弈</h2>
<ul>
<li>正常形式博弈不涉及行动顺序与时间</li>
<li>扩展形式博弈考虑时序影响，包括信息对称与不对称两种</li>
<li>有限信息对称博弈用（N, A, H, Z, χ, ρ, σ, u）来表示</li>
<li>N代表n个参与者</li>
<li>A代表一组行动</li>
<li>H代表一组非终点的选择节点</li>
<li>行动函数 $:H 2^A $ 表示每个选择节点的可能行动</li>
<li>参与者函数 <span class="math inline">\(\rho:H \rightarrow N\)</span> 表示在节点h上采取行动的选手 <span class="math inline">\(i\in N\)</span></li>
<li>Z代表终止节点</li>
<li>后继者函数 <span class="math inline">\(\sigma:H\times A\rightarrow H \cup Z\)</span>映射一个选择节点和一个行动对于所有的节点与行动，如果后继者函数相同，那么节点与行动相同</li>
<li>效用函数<span class="math inline">\(u=(u_1,...,u_n);u_i:Z\rightarrow R\)</span> 表示在终止节点上参与者的效用</li>
<li>信息对称扩展形式博弈里参与者的纯策略是行动函数的乘积<span class="math inline">\(\prod_{h\in H,\rho(h)=i}\chi(h)\)</span></li>
<li>扩展形式博弈可以转为正常形式博弈，但是有大量冗余，正常形式博弈不一定可转化为扩展形式博弈</li>
<li>信息对称扩展形式博弈都有纯策略纳什均衡</li>
</ul>
</div>
<div id="section-24.11" class="section level2">
<h2><span class="header-section-number">24.11</span> 完美子博弈</h2>
<ul>
<li>在节点h的子博弈G是节点集合H对博弈G的限制</li>
<li>完美子博弈均衡也是纳什均衡，但不考虑无信用恐吓</li>
<li>倒推法：从最低层寻找纳什均衡，逐层反推排除掉其他选择得到策略</li>
<li>对于零和博弈，倒推法实际就是最小最大算法</li>
</ul>
</div>
<div id="section-24.12" class="section level2">
<h2><span class="header-section-number">24.12</span> 信息不对称扩展形式博弈</h2>
<ul>
<li>参与者选择节点被分配到不同信息集合里，个体无法区分选择节点</li>
<li>信息不对称博弈用（N, A, H, Z, χ, ρ, σ, u, I）来表示</li>
<li>对于<span class="math inline">\(I = (I_1,...,I_n)\)</span>，<span class="math inline">\(I_i = (I_{i,1},...,I_{i,k_i})\)</span>是依赖于<span class="math inline">\({h\in H: \pho (h) = i}\)</span>的平衡，具有当存在j在节点<span class="math inline">\(h\in I_{i,j}\)</span>与<span class="math inline">\(h&#39;\in I_{i,j}\)</span>时，有<span class="math inline">\(\chi(h) = \chi(h&#39;)\)</span>与<span class="math inline">\(\rho(h) = \rho(h&#39;)\)</span>的属性</li>
</ul>
</div>
<div id="section-24.13" class="section level2">
<h2><span class="header-section-number">24.13</span> 混合与行为策略</h2>
<ul>
<li>混合策略随机化纯策略</li>
<li>行为策略是遇到每个信息集后的抛硬币</li>
</ul>
</div>
<div id="section-24.14" class="section level2">
<h2><span class="header-section-number">24.14</span> 重复博弈</h2>
<ul>
<li>参与者<span class="math inline">\(i\)</span>给定一个无限序列<span class="math inline">\(r_1,r_2,...\)</span>，其平均回报是<span class="math inline">\(\lim_{k\rightarrow\infty}\sum_{j=1}^k\frac{r_j}{k}\)</span></li>
<li>考虑折扣因子<span class="math inline">\(\beta\)</span>，未来折扣回报是<span class="math inline">\(\sum_{j=1}^{\infty}\beta^jr_j\)</span>，一般人会更关注当下，对未来关注不会超过当下，但以<span class="math inline">\(1-\beta\)</span>的概率终止博弈</li>
</ul>
</div>
<div id="stochastic-game" class="section level2">
<h2><span class="header-section-number">24.15</span> 随机博弈（stochastic game）</h2>
<ul>
<li>随机博弈是重复博弈的泛化，每一次都取决于上一次博弈结果</li>
<li>用(Q, N, A, P, R)来表示</li>
<li>Q代表有限状态集</li>
<li>N代表有限参与者集合</li>
<li><span class="math inline">\(A = A_1 \times ... \times A_n\)</span> 其中<span class="math inline">\(A_i\)</span>是参与者i的有限行动集</li>
<li><span class="math inline">\(P:Q \times A \times Q \rightarrow[0,1]\)</span>表示转移概率函数，从状态Q采取行动A变化另一个状态Q</li>
<li><span class="math inline">\(R = r_1,...,r_n\)</span>中<span class="math inline">\(r_i:Q\times A\rightarrow R\)</span> 表示参与者i的效用函数</li>
</ul>
</div>
<div id="fictitious-play" class="section level2">
<h2><span class="header-section-number">24.16</span> 虚拟行动（fictitious play）</h2>
<ul>
<li>对于行动<span class="math inline">\(a\in A\)</span>，用<span class="math inline">\(w(a)\)</span>表示对手行动次数，可以非零初始化</li>
<li>用这个数字评价对手策略 <span class="math inline">\(\sigma(a) = \frac{w(a)}{\sum_{a&#39; \in A}w(a&#39;)}\)</span></li>
<li>在虚拟行动中每一个参与者的策略经验分布收敛，那么一定收敛到纳什均衡</li>
</ul>
</div>
<div id="no-regret-learning" class="section level2">
<h2><span class="header-section-number">24.17</span> 无悔学习（No-regret learning）</h2>
<ul>
<li>后悔表示参与者在时间t上没有采用策略s<span class="math inline">\(R^t(s) = max(\alpha^t(s)-\alpha^t,0)\)</span></li>
<li>无悔学习表现出对任何纯策略有<span class="math inline">\(Pr([\lim \inf R^t(s)]\leq0)\)</span></li>
<li>在每一步每个行为正比于其后悔<span class="math inline">\(\sigma_i^{t+1}(s) = \frac{R^t(s)}{\sum_{s&#39;\in S_i}R^t(s&#39;)}\)</span></li>
<li>对有限博弈收敛到均衡</li>
</ul>
</div>
<div id="section-24.18" class="section level2">
<h2><span class="header-section-number">24.18</span> 无限重复博弈的平衡</h2>
<ul>
<li>著名的策略包括以牙还牙（tit-for-tat）跟扳机（trigger）</li>
<li>纳什均衡只适用于有限博弈</li>
<li>无限策略里有无限个纯策略均衡</li>
<li>对于n个参与者的博弈<span class="math inline">\(G = (N,A,u)\)</span>其收益向量<span class="math inline">\(r = (r_1,r_2,...,r_n)\)</span>，让<span class="math inline">\(v_i = min_{s_{-i} \in S_{-i}max_{s_i \in S_i}} u_i(s_{-i},s_i)\)</span> i的最小最大值是对方使用最小最大策略时其收益</li>
<li>一个收益向量r是增强的如果<span class="math inline">\(r_i\geq v_i\)</span></li>
<li>一个收益向量是可行的当存在非负值<span class="math inline">\(\alpha_a\)</span>对于所有i，有<span class="math inline">\(\sum_{a\in A}\alpha_au_i(a)\)</span>且<span class="math inline">\(\sum_{a\in A}\alpha_a = 1\)</span></li>
<li>无名氏定理（folk theorem）：如果收益向量对无限博弈的纳什均衡是平均回报，那么对每个参与者都是增强的，如果可行且增强，收益向量就是有平均回报的无限纳什均衡</li>
</ul>
</div>
<div id="section-24.19" class="section level2">
<h2><span class="header-section-number">24.19</span> 贝叶斯博弈</h2>
<ul>
<li>贝叶斯博弈<span class="math inline">\((N,G,P,I)\)</span>里，N代表参与者集合，G代表博弈集合，P代表对某个博弈集合的先验概率，I代表G里面对每个参与者的组成部分</li>
<li>也可以用认知类型来定义<span class="math inline">\(N,A,\Theta,p,u\)</span>，A表示行为集合，<span class="math inline">\(\Theta\)</span>表示对参与者i的类型空间，p表示没中类型的先验概率，u表示某类型某行动对参与者i的收益</li>
<li>贝叶斯纳什均衡：最大化每个参与者每种行动类型收益的策略，可以是纯策略，也可以是混合策略</li>
<li>三种类型：对自己对方都不知道（现存），知道自己不知道对方(过渡)，都知道（过后）</li>
<li>过渡态期望收益：<span class="math inline">\(EU_i(s|\theta_i) = \sum_{\theta_{-i}\in\Theta_{-i}}p(\theta_{-i}|\theta_i)\sum_{a\in A}(\prod_{j\in N}s_j(a_j|\theta_j))u_i(a,\theta_i,\theta_{-i})\)</span></li>
<li>现存期望收益：<span class="math inline">\(EU_i(s) = \sum_{\theta_i\in \Theta_i}p(\theta_i)EU_i(s|\theta_i)\)</span></li>
<li>贝叶斯均衡混合策略<span class="math inline">\(s_i\in arg max_{s&#39;_i}EU_i(s&#39;_i,s_{-i}|\theta_i)\)</span></li>
<li>给定一方行为，考虑先验概率另一方收益最大时的博弈平衡</li>
</ul>
</div>
<div id="section-24.20" class="section level2">
<h2><span class="header-section-number">24.20</span> 联盟博弈</h2>
<ul>
<li>收益可转移的联盟博弈（N,v）N代表有限的参与者，<span class="math inline">\(v:2^N \rightarrow R\)</span> 里每个联盟 <span class="math inline">\(S\subseteq N\)</span> 里的能够分配的收益，假定<span class="math inline">\(v(\varnothing)=0\)</span></li>
<li>联盟博弈解决的问题是哪些联盟会生成及收益如何分配</li>
<li>超加性博弈<span class="math inline">\(G=(N,v)\)</span>表示对于所有的<span class="math inline">\(S,T\subset N\)</span>，如果<span class="math inline">\(S\cap T = \varnothing\)</span>，那么有<span class="math inline">\(v(S\cup T\geq v(S)+v(T))\)</span>，这种情况下整体绑定为一个联盟收益最高</li>
</ul>
</div>
<div id="shapley-value" class="section level2">
<h2><span class="header-section-number">24.21</span> 夏普利值（Shapley Value）</h2>
<ul>
<li>如何公平分割收益，Lloyd Shapley认为参与者要按照边际贡献的比例获得收益</li>
<li><p>公理 - 对于每一种收益方法如果两个人可相互交换<span class="math inline">\(v(S\cup \{i\}) = v(S\cup \{j\}))\)</span>，那么其收益相等<span class="math inline">\(\psi_i(N,v)=\psi_j(N,v)\)</span> - 如果某个人不产生收益<span class="math inline">\(v(S\cup \{i\} = v(S))\)</span>，那么不分成<span class="math inline">\(\psi_i(N,v)=0\)</span> - 对于<span class="math inline">\(v_1\)</span>和<span class="math inline">\(v_2\)</span>，博弈<span class="math inline">\((N,v_1+v_2)\)</span>用<span class="math inline">\((v_1+v_2)(S)=v_1(S)+v_2(S)\)</span>定义，有<span class="math inline">\(\psi_i(N,v_1+v_2)=\psi_i(N,v_1)+\psi_i(N,v2)\)</span></p></li>
<li><p>夏普利值按照$<em>i(N,v) = </em>{SN_i} |S|!(|N|-|S|-1[v(S{i})-v(S)]) $ 分配收益，也就是满足上面三个公理的分配方式</p></li>
</ul>
</div>
<div id="section-24.22" class="section level2">
<h2><span class="header-section-number">24.22</span> 核心</h2>
<ul>
<li>夏普利值分配比较公平，但不一定稳定，不容易形成大联盟</li>
<li>核心指对于<span class="math inline">\(S\subseteq N\)</span>，有<span class="math inline">\(\sum_{i\in S} x_i \geq v(S)\)</span> ，总和收益至少不低于内部小联盟收益</li>
<li>核心可能是空的且不唯一</li>
<li>对于简单博弈核心是空的当且仅当没有否决参与者，如果有否决参与者，核心包括所有非否决参与者收益0的收益向量</li>
<li>凸博弈：<span class="math inline">\(v(S\cup T)\geq v(S)+v(T)-v(S\cap T)\)</span>，每个凸博弈有一个非空核心且是夏普利值</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="section-23.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="section-25.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yufree/notes/edit/master/24-gametheroy.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
