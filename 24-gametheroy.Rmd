# 博弈论

## 术语

- 参与者（players） $N= {1,...,n}$
- 参与者 $i$ 有一组行动（Actions），行动的集合 $a=(a_1,...,a_n) \in A=A_1 \times A_2 \times ... \times A_n$
- 参与者 $i$ 的每个行为的收益（Payoffs）都可以用 $u_i:A \rightarrow \Re$ 这个函数表示 $u_i(a)$ 表示某个行为产生的收益，$u = (u_i,...,u_n)$是效用函数的集合
- n个参与者的标准博弈（normal form） $\langle N,A,u \rangle$
- 两人博弈可以用矩阵（matrix）来描述，行代表选手1，列代表选手2，行对应选手1的行动 $a_1 \in A_1$，列对应选手2的行动 $a_2 \in A_2$，每个单元列出每个参与者的收益，先行选手，后列选手
- 纯竞争博弈（Games of Pure competition）：两个参与者收益对立且对于所有行动集合 $a \in A, u_1(a)+u_2(a) = c$，$c$是常数，零和博弈是一个常数为0的纯竞争博弈，此时我们只用考虑一个参与者的收益函数就可以了

## 支配策略（dominate strategy）

- 行动单一称为纯策略（pure strategies）有一定概率分布的行动策略称为混合策略（mixed strategies）
- 对于一个参与者，不论其它参与者采取任何策略，某策略都会得到最大的收益
- $a_i \in a_i$ 为强支配策略当且仅当参与者$i$ 的收益 $u_i(a_i,a_{-i}) > u_i(a'_i,a_{-i})$，如果 $a'_i = a_i$，那么为弱支配策略

## 最佳回应（Best respinse）

- 对于一个参与者，当已知其他参与者的行为后，收益最大的策略
- 参与者$i$，对于其它参与者的策略$a_{-i} \in a_{-i}$ 的策略如果$u_i(a_i,a_{-i}) \geqslant u_i(a'_i,a_{-i})$

## 纳什均衡（Nash Equilibrium）

- $a = \langle a_1,...,a_n\rangle$ 是一个纯策略纳什均衡当且仅当对于任何一个行为i，有$a_i \in BR(a_{-i})$
- 如果任何参与者改变行为的收益都不会增加，那么此时进入纳什均衡
- 纳什均衡是一系列行为的列表，这些行为都是稳定的
- 支配策略是纳什均衡但反过来不一定对
- 任何有限博弈都存在一个纳什均衡（纳什1950年提出）

## 帕累托最优（Pareto Optimality）

- 某个结果是帕累托最优当且仅当没有其他结果可以全局帕累托支配这个结果
- 帕累托最优表示某个博弈结果不差于其他博弈结果
- 纳什均衡不一定是帕累托最优（囚徒困境）

## 混合策略（Mixed stratergies）

- 策略$S_i$指对于每个参与者行动的概率分布集合
- 概率 $Pr(a|s) = \prod_{j \in N}s_j(a_j)$
- 期望收益函数 $u_i(s) = \sum_{a \in A} u_i(a)Pr(a|s)$
- 随机策略会使对手混乱进入动态，很多博弈只存在混合策略纳什均衡而没有纯策略纳什均衡（石头剪子布）

## 寻找纳什均衡

- 两人博弈可以用线性互补算法（Linear Complementarity）求解
- 严格说因为一定存在纳什均衡，寻找它不是NPC问题，但是是PPAD问题，后来人证明纳什均衡是PPAD问题
- PPAD问题包括P问题的同时属于NP问题，指存在多项式的解，但不好找
- P问题指多项式时间可解决的问题
- NP问题指多项式时间可验证一个解的问题
- NPC问题指NP问题的归约问题，同时也是NP问题，复杂度不断提高，NPC问题的存在让$P = NP$ 问题很难有答案
- NP-hard问题指NP问题的归约问题，但不一定是NP问题

## 被支配策略（dominated strategy）

- 指不论其他参与者采取任何策略，该策略劣于其他策略
- 被支配策略永远不会是最佳回应
- 可以交互地去除掉每个选手的被支配策略

## 最大最小策略（Maxmin strategies）

- 指其他参与者对某参与者最小收益策略下的最大收益策略$arg max_{s_i}min_{s_{-i}}u_i(s_1,s_2)$
- 最小最大策略指让对方收益最大而自己收益最小的策略$arg min_{s_i}max_{s_{-i}}u_{-i}i(s_1,s_2)$

## 扩展形式博弈

- 正常形式博弈不涉及行动顺序与时间
- 扩展形式博弈考虑时序影响，包括信息对称与不对称两种
- 有限信息对称博弈用（N, A, H, Z, χ, ρ, σ, u）来表示
- N代表n个参与者
- A代表一组行动
- H代表一组非终点的选择节点
- 行动函数 $\chi:H \rightarrow 2^A $ 表示每个选择节点的可能行动
- 参与者函数 $\rho:H \rightarrow N$ 表示在节点h上采取行动的选手 $i\in N$
- Z代表终止节点
- 后继者函数 $\sigma:H\times A\rightarrow H \cup Z$映射一个选择节点和一个行动对于所有的节点与行动，如果后继者函数相同，那么节点与行动相同
- 效用函数$u=(u_1,...,u_n);u_i:Z\rightarrow R$ 表示在终止节点上参与者的效用
- 信息对称扩展形式博弈里参与者的纯策略是行动函数的乘积$\prod_{h\in H,\rho(h)=i}\chi(h)$
- 扩展形式博弈可以转为正常形式博弈，但是有大量冗余，正常形式博弈不一定可转化为扩展形式博弈
- 信息对称扩展形式博弈都有纯策略纳什均衡

## 完美子博弈

- 在节点h的子博弈G是节点集合H对博弈G的限制
- 完美子博弈均衡也是纳什均衡，但不考虑无信用恐吓
- 倒推法：从最低层寻找纳什均衡，逐层反推排除掉其他选择得到策略
- 对于零和博弈，倒推法实际就是最小最大算法

## 信息不对称扩展形式博弈

- 参与者选择节点被分配到不同信息集合里，个体无法区分选择节点
- 信息不对称博弈用（N, A, H, Z, χ, ρ, σ, u, I）来表示
- 对于$I = (I_1,...,I_n)$，$I_i = (I_{i,1},...,I_{i,k_i})$是依赖于${h\in H: \pho (h) = i}$的平衡，具有当存在j在节点$h\in I_{i,j}$与$h'\in I_{i,j}$时，有$\chi(h) = \chi(h')$与$\rho(h) = \rho(h')$的属性

## 混合与行为策略

- 混合策略随机化纯策略
- 行为策略是遇到每个信息集后的抛硬币

## 重复博弈

- 参与者$i$给定一个无限序列$r_1,r_2,...$，其平均回报是$\lim_{k\rightarrow\infty}\sum_{j=1}^k\frac{r_j}{k}$
- 考虑折扣因子$\beta$，未来折扣回报是$\sum_{j=1}^{\infty}\beta^jr_j$，一般人会更关注当下，对未来关注不会超过当下，但以$1-\beta$的概率终止博弈

## 随机博弈（stochastic game）

- 随机博弈是重复博弈的泛化，每一次都取决于上一次博弈结果
- 用(Q, N, A, P, R)来表示
- Q代表有限状态集
- N代表有限参与者集合
- $A = A_1 \times ... \times A_n$ 其中$A_i$是参与者i的有限行动集
- $P:Q \times A \times Q \rightarrow[0,1]$表示转移概率函数，从状态Q采取行动A变化另一个状态Q
- $R = r_1,...,r_n$中$r_i:Q\times A\rightarrow R$ 表示参与者i的效用函数

## 虚拟行动（fictitious play）

- 对于行动$a\in A$，用$w(a)$表示对手行动次数，可以非零初始化
- 用这个数字评价对手策略 $\sigma(a) = \frac{w(a)}{\sum_{a' \in A}w(a')}$
- 在虚拟行动中每一个参与者的策略经验分布收敛，那么一定收敛到纳什均衡

## 无悔学习（No-regret learning）

- 后悔表示参与者在时间t上没有采用策略s$R^t(s) = max(\alpha^t(s)-\alpha^t,0)$
- 无悔学习表现出对任何纯策略有$Pr([\lim \inf R^t(s)]\leq0)$
- 在每一步每个行为正比于其后悔$\sigma_i^{t+1}(s) = \frac{R^t(s)}{\sum_{s'\in S_i}R^t(s')}$
- 对有限博弈收敛到均衡

## 无限重复博弈的平衡

- 著名的策略包括以牙还牙（tit-for-tat）跟扳机（trigger）
- 纳什均衡只适用于有限博弈
- 无限策略里有无限个纯策略均衡
- 对于n个参与者的博弈$G = (N,A,u)$其收益向量$r = (r_1,r_2,...,r_n)$，让$v_i = min_{s_{-i} \in S_{-i}max_{s_i \in S_i}} u_i(s_{-i},s_i)$ i的最小最大值是对方使用最小最大策略时其收益
- 一个收益向量r是增强的如果$r_i\geq v_i$
- 一个收益向量是可行的当存在非负值$\alpha_a$对于所有i，有$\sum_{a\in A}\alpha_au_i(a)$且$\sum_{a\in A}\alpha_a = 1$
- 无名氏定理（folk theorem）：如果收益向量对无限博弈的纳什均衡是平均回报，那么对每个参与者都是增强的，如果可行且增强，收益向量就是有平均回报的无限纳什均衡